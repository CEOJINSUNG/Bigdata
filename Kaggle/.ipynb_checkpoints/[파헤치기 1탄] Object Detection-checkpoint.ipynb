{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo v3 Object Detection in Tensorflow 파헤치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 자료는 Kaggle 내 Open Source 중 Object Detection Model들을 좀더 알아보기 쉽게 학습하기 위해 만들어졌습니다. \n",
    "- 출처 : https://www.kaggle.com/aruchomu/yolo-v3-object-detection-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Yolo란 무엇일까?\n",
    "\n",
    "- 욜로는 object detection을 위한 CNN을 사용하는 알고리즘으로 기존의 다른 알고리즘에 비하면 class label들을 예측하고 물건의 장소들도 탐지할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dependency\n",
    "\n",
    "- Yolo 설치를 위해서는 Tensorflow(Deep learning), NumPy(numerical computation)과 Pillow(Image Processing) 라이브러리들이 필요하다. 또한 박스 색깔들을 위한 seaborn의 color palette도 사용해야한다. 그리고 노트북에 있는 이미지들을 보여주기 위한 IPython 내 display() 함수도 가져와야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe00254bd799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolor_palette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model hyperparameters\n",
    "\n",
    "- Yolo를 위한 여러 수치들을 설정해준다.\n",
    "- Hyperparameter : 머신러닝에서 하이퍼 파라미터는 학습 프로세스가 시작되기 전에 값이 설정되는 매개 변수를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "           (30, 61), (62, 45), (59, 119),\n",
    "           (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch normalization\n",
    "\n",
    "- Batch normalization은 학습과정에서 각 배치별로 평균과 분산을 이용해 정규화하는 것을 의미한다.\n",
    "- 거의 욜로 내 모든 계층들은 Batch normalization을 가지고 있으며 이것은 학습을 좀더 빠르게 하고 단위들간 분산들도 줄여주는 역할을 한다. \n",
    "- BATCH_NORM_EPSILON는 공식 내 epsilon들을 의미하고 BATCH_NORM_DECAY는 평균과 분산을 움직이는 컴퓨팅 모멘트를 의미한다.\n",
    "- 공식 참고 : moving_average = momentum * moving_average + (1 - momentum) * current_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaky ReLU\n",
    "\n",
    "- Leaky ReLU는 ReLU 활성함수를 조금 변형시킨 것으로 이 아이디어는 많은 수의 활성들이 0 이되는 \"neuron dying\"을  방지하는 것에서 착안이 되었다.\n",
    "- LEAKY_RELU는 다음 함수의 알파를 의미한다.f(x)={(x>0) x, (x<0) 알파*x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchors\n",
    "\n",
    "- Anchors는 bounding box priors의 종류들이고 이는 k-means 클러스터링을 사용한 데이터에서 계산된 것이다. 우리는 클러스터 중심의 더해진 값으로 박스의 넓이 높이들을 예측하고 시그모이드 함수를 활용하여 박스의 중심좌표들을 예측할 것이다.\n",
    "- Bounding Box Prior란? 디지털 이미지 처리에서 bounding box는 화면상에 이미지가 있을때 이 이미지를 감싸주는 사각형 박스들의 좌표들을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model definition\n",
    "\n",
    "#### Batch norm and fixed padding\n",
    "\n",
    "- batch_norm 함수는 배치정규화 모델에서 변수들과 함꼐 사용되기 때문에 유용하다. 또한 ResNet에서 Yolo는 고정된 padding 값으로 합성곱을 사용한다. 이는 오직 커널 사이즈에 의해 paddin이 정해진다는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "    \"\"\"표준 변수들을 활용하여 배치정규화를 수행함.\"\"\"\n",
    "    return tf.layers.batch_nomalization(inputs=inputs, axis=1\n",
    "            if data_format == 'channels_first' else 3, \n",
    "            momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, scale=Treu, training=training)\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \"\"\"고정된 padding의 ResNet 이행.\n",
    "    \n",
    "    입력된 사이즈의 부분적 크기에 따라 입력을 패드시킨다.\n",
    "    \n",
    "    인수:\n",
    "        입력값: Tensor input to be padded.\n",
    "        커널 사이즈: The kernel to be used in the conv2d or max_pool2d.\n",
    "        데이터 형식: 입력값 형식\n",
    "    \n",
    "    반환값:\n",
    "        A tensor with the same format as the input(같은 형식의 인풋을 받아내겠다는 의미)\n",
    "    \"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0,0]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [ [[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]]])\n",
    "    return padded_inputs\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "    \"\"\"Strided 2-D convolution with explicit padding\"\"\"\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "    \n",
    "    return tf.layers.conv2d(\n",
    "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
    "        use_bias=False, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특징 추출기: Darknet-53\n",
    "\n",
    "- 특징 추출을 위해서 욜로는 ImageNet에서 이미 훈련된 Darknet-53 신경망을 사용한다. 이는 ResNet과 같이, 정보가 더 멀리 나갈 수 있도록 도와주는 shorcut (residual) connection들을 가지고 있다. 마지막 3개의 층(Avgpool. Connected and Softmax)들을 생략시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format, strides=1):\n",
    "    \"\"\"Darknet의 Residual Block 생성하기\"\"\"\n",
    "    shortcut=inputs\n",
    "    \n",
    "    inputs = conv2d_fixxed_padding(inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs += shortcut\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "def darknet53(inputs, training, data_format):\n",
    "    \"\"\"특징추출하기 위한 Darknet53 모델 만들기\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
    "                                      data_format=data_format)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(2):\n",
    "        inputs = darknet53_residual_block(inputs, filters=64,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=128,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    route1 = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    route2 = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    return route1, route2, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convoution layers(합성곱 계층)\n",
    "\n",
    "- 욜로는 많은 수의 합성곱 계층들을 가지고 있고 이들을 블록으로 묶는 것이 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    \"\"\"Darknet 뒤에 수행되는 합성곱 계층들을 만들고 있다\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    route = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    return route, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detection layers\n",
    "\n",
    "- 욜로는 3개의 서로 다른 크기의 규모를 탐지하는 3개의 Dectection layer를 가지고 있다. 각각은 1x1 층을 사용하여 'n_anchors * (5 + n_classes)' 값을 예측한다. 각 규모마다 'n_anchors = 3. 5 + n_classes' 박스의 4개의 좌표들, 물건일 가능성, 클래스의 가능성을 예측하는 3개의 anchor들을 각각 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    \"\"\"Yolo 마지막 detection layer 만들기\n",
    "\n",
    "    anchor에 관한 박스들을 탐지한다.\n",
    "\n",
    "    인수:\n",
    "        inputs: Tensor input\n",
    "        n_classes: 라벨 수들\n",
    "        anchors: anchor 크기목록\n",
    "        img_size: 모델의 입력받은 크기\n",
    "        data_format: 입력값 형식.\n",
    "\n",
    "    반환값:\n",
    "        Tensor output.\n",
    "    \"\"\"\n",
    "    n_anchors = len(anchors)\n",
    "\n",
    "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
    "                              kernel_size=1, strides=1, use_bias=True,\n",
    "                              data_format=data_format)\n",
    "\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
    "                                 5 + n_classes])\n",
    "\n",
    "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "\n",
    "    box_centers, box_shapes, confidence, classes = \\\n",
    "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
    "\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x, y)\n",
    "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "\n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "\n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "\n",
    "    inputs = tf.concat([box_centers, box_shapes,\n",
    "                        confidence, classes], axis=-1)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsample layer(분류되지 않은 층)\n",
    "\n",
    "- 다른 크기의 탐지를 적용하기 전에 Darknet-53의 짧은 아웃풋을 합치기 위해서 가장 가까운 점에 연결하는 방법을 사용하여 특징지도를 분류하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "    \"\"\"가장 가까운 점을 연결하는 방법을 사용하여 'out_shape'에 분류되지 않게 함\"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMS(Non-max suppression)\n",
    "\n",
    "- 이 모델은 많은 박스들을 만들고 낮은 점수의 박스들을 버린다. 또한 하나의 물건에 복잡한 박스들을 가지게 하는 것을 피하기 위하여 각 층마다 NMS를 활용하여 많이 겹쳐진 박스들도 버린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boxes(inputs):\n",
    "    \"\"\"박스 위아래좌우 위치를 계산한다.\"\"\"\n",
    "    center_x, center_y, width, height, confidence, classes = \\\n",
    "        tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)\n",
    "\n",
    "    top_left_x = center_x - width / 2\n",
    "    top_left_y = center_y - height / 2\n",
    "    bottom_right_x = center_x + width / 2\n",
    "    bottom_right_y = center_y + height / 2\n",
    "\n",
    "    boxes = tf.concat([top_left_x, top_left_y,\n",
    "                       bottom_right_x, bottom_right_y,\n",
    "                       confidence, classes], axis=-1)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold,\n",
    "                        confidence_threshold):\n",
    "    \"\"\"각 층마다 분리해 NMS를 실행시킨다.\n",
    "\n",
    "    인수:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: 계층들의 개수.\n",
    "        max_output_size: 각 층마다 선택된 박스의 최대 개수\n",
    "        iou_threshold: IOU 임계치(IoU = 교집합 영역 넓이 / 합집합 영역 넓이)\n",
    "        confidence_threshold: Threshold for the confidence score.\n",
    "    반환:\n",
    "        배치 안에 있는 각 샘플마다의 박스 목록\n",
    "    \"\"\"\n",
    "    batch = tf.unstack(inputs)\n",
    "    boxes_dicts = []\n",
    "    for boxes in batch:\n",
    "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
    "        classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
    "        classes = tf.expand_dims(tf.to_float(classes), axis=-1)\n",
    "        boxes = tf.concat([boxes[:, :5], classes], axis=-1)\n",
    "\n",
    "        boxes_dict = dict()\n",
    "        for cls in range(n_classes):\n",
    "            mask = tf.equal(boxes[:, 5], cls)\n",
    "            mask_shape = mask.get_shape()\n",
    "            if mask_shape.ndims != 0:\n",
    "                class_boxes = tf.boolean_mask(boxes, mask)\n",
    "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,\n",
    "                                                              [4, 1, -1],\n",
    "                                                              axis=-1)\n",
    "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
    "                indices = tf.image.non_max_suppression(boxes_coords,\n",
    "                                                       boxes_conf_scores,\n",
    "                                                       max_output_size,\n",
    "                                                       iou_threshold)\n",
    "                class_boxes = tf.gather(class_boxes, indices)\n",
    "                boxes_dict[cls] = class_boxes[:, :5]\n",
    "\n",
    "        boxes_dicts.append(boxes_dict)\n",
    "\n",
    "    return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model class\n",
    "\n",
    "- 이전에 사용한 모든 층들을 활용해 모델링을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v3:\n",
    "    \"\"\"Yolo v3 model class.\"\"\"\n",
    "\n",
    "    def __init__(self, n_classes, model_size, max_output_size, iou_threshold,\n",
    "                 confidence_threshold, data_format=None):\n",
    "        \"\"\"모델 생성\n",
    "\n",
    "        인수:\n",
    "            n_classes: 클래스 라벨 개수\n",
    "            model_size: 모델의 입력받은 크기\n",
    "            max_output_size: 각 층마다 선택된 박스의 최대 개수\n",
    "            iou_threshold: IOU 임계치(IoU = 교집합 영역 넓이 / 합집합 영역 넓이)\n",
    "            confidence_threshold: Threshold for the confidence score.\n",
    "            data_format: 인풋 데이터 형식\n",
    "\n",
    "        반환:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        if not data_format:\n",
    "            if tf.test.is_built_with_cuda():\n",
    "                data_format = 'channels_first'\n",
    "            else:\n",
    "                data_format = 'channels_last'\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.model_size = model_size\n",
    "        self.max_output_size = max_output_size\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.data_format = data_format\n",
    "\n",
    "    def __call__(self, inputs, training):\n",
    "        \"\"\"입력받은 이미지의 배치를 위한 박스들을 감지하는 작동방법을 더해줌\n",
    "\n",
    "        인수:\n",
    "            inputs: A Tensor representing a batch of input images.\n",
    "            training: A boolean, whether to use in training or inference mode.\n",
    "\n",
    "        반환:\n",
    "            배치 안에 있는 각 샘플마다의 박스 목록\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('yolo_v3_model'):\n",
    "            if self.data_format == 'channels_first':\n",
    "                inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "            inputs = inputs / 255\n",
    "\n",
    "            route1, route2, inputs = darknet53(inputs, training=training,\n",
    "                                               data_format=self.data_format)\n",
    "\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=512, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect1 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[6:9],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
    "                                          data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training,\n",
    "                                data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route2.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                              data_format=self.data_format)\n",
    "            axis = 1 if self.data_format == 'channels_first' else 3\n",
    "            inputs = tf.concat([inputs, route2], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=256, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect2 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[3:6],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1,\n",
    "                                          data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training,\n",
    "                                data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route1.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                              data_format=self.data_format)\n",
    "            inputs = tf.concat([inputs, route1], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=128, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect3 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[0:3],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
    "\n",
    "            inputs = build_boxes(inputs)\n",
    "\n",
    "            boxes_dicts = non_max_suppression(\n",
    "                inputs, n_classes=self.n_classes,\n",
    "                max_output_size=self.max_output_size,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                confidence_threshold=self.confidence_threshold)\n",
    "\n",
    "            return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Utility functions\n",
    "\n",
    "- 파일로부터 클래스 이름, Numpy 배열과 같은 이미지들을 업로드 하고 예측된 박스들을 그려주는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_names, model_size):\n",
    "    \"\"\"4D 배열로 이미지를 업로드한다\n",
    "\n",
    "    인수:\n",
    "        img_names: 이미지 이름 목록\n",
    "        model_size: 모델의 입력받은 크기\n",
    "        data_format: 반환된 배열 형식\n",
    "            ('channels_first' or 'channels_last').\n",
    "\n",
    "    반환:\n",
    "        4D Numpy 배열\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "\n",
    "    for img_name in img_names:\n",
    "        img = Image.open(img_name)\n",
    "        img = img.resize(size=model_size)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_class_names(file_name):\n",
    "    \"\"\"파일 이름으로 부터 클래스 이름 목록을 반환함\"\"\"\n",
    "    with open(file_name, 'r') as f:\n",
    "        class_names = f.read().splitlines()\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
    "    \"\"\"탐지된 박스들을 그림\n",
    "\n",
    "    인수:\n",
    "        img_names: 입력받은 이미지 이름 목록\n",
    "        boxes_dict: A class-to-boxes dictionary.\n",
    "        class_names: 클래스 이름 목록\n",
    "        model_size: 모델의 입력받은 크기\n",
    "\n",
    "    반환:\n",
    "        없음\n",
    "    \"\"\"\n",
    "    colors = ((np.array(color_palette(\"hls\", 80)) * 255)).astype(np.uint8)\n",
    "    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names,\n",
    "                                         boxes_dicts):\n",
    "        img = Image.open(img_name)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(font='../input/futur.ttf',\n",
    "                                  size=(img.size[0] + img.size[1]) // 100)\n",
    "        resize_factor = \\\n",
    "            (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
    "        for cls in range(len(class_names)):\n",
    "            boxes = boxes_dict[cls]\n",
    "            if np.size(boxes) != 0:\n",
    "                color = colors[cls]\n",
    "                for box in boxes:\n",
    "                    xy, confidence = box[:4], box[4]\n",
    "                    xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
    "                    x0, y0 = xy[0], xy[1]\n",
    "                    thickness = (img.size[0] + img.size[1]) // 200\n",
    "                    for t in np.linspace(0, 1, thickness):\n",
    "                        xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
    "                        xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
    "                        draw.rectangle(xy, outline=tuple(color))\n",
    "                    text = '{} {:.1f}%'.format(class_names[cls],\n",
    "                                               confidence * 100)\n",
    "                    text_size = draw.textsize(text, font=font)\n",
    "                    draw.rectangle(\n",
    "                        [x0, y0 - text_size[1], x0 + text_size[0], y0],\n",
    "                        fill=tuple(color))\n",
    "                    draw.text((x0, y0 - text_size[1]), text, fill='black',\n",
    "                              font=font)\n",
    "\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Converting weights to Tensorflow format\n",
    "\n",
    "-  파일들을 반복시켜 'tf.assign' 작동법을 점진적으로 생성시키고 가중치를 적용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(variables, file_name):\n",
    "    \"\"\"미리 훈련된 욜로 가중치를 업로드하고 모양을 다시 잡음\n",
    "\n",
    "    인수:\n",
    "        variables: 배정받은 tf.Variable 목록\n",
    "        file_name: 가중치를 포함한 파일 이름\n",
    "\n",
    "    반환:\n",
    "        assign 작동 목록\n",
    "    \"\"\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        # Skip first 5 values containing irrelevant info\n",
    "        np.fromfile(f, dtype=np.int32, count=5)\n",
    "        weights = np.fromfile(f, dtype=np.float32)\n",
    "\n",
    "        assign_ops = []\n",
    "        ptr = 0\n",
    "\n",
    "        # Load weights for Darknet part.\n",
    "        # Each convolution layer has batch normalization.\n",
    "        for i in range(52):\n",
    "            conv_var = variables[5 * i]\n",
    "            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
    "            batch_norm_vars = [beta, gamma, mean, variance]\n",
    "\n",
    "            for var in batch_norm_vars:\n",
    "                shape = var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(var, var_weights))\n",
    "\n",
    "            shape = conv_var.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "        # Loading weights for Yolo part.\n",
    "        # 7th, 15th and 23rd convolution layer has biases and no batch norm.\n",
    "        ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
    "        unnormalized = [6, 13, 20]\n",
    "        for j in range(3):\n",
    "            for i in ranges[j]:\n",
    "                current = 52 * 5 + 5 * i + j * 2\n",
    "                conv_var = variables[current]\n",
    "                gamma, beta, mean, variance =  \\\n",
    "                    variables[current + 1:current + 5]\n",
    "                batch_norm_vars = [beta, gamma, mean, variance]\n",
    "\n",
    "                for var in batch_norm_vars:\n",
    "                    shape = var.shape.as_list()\n",
    "                    num_params = np.prod(shape)\n",
    "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                    ptr += num_params\n",
    "                    assign_ops.append(tf.assign(var, var_weights))\n",
    "\n",
    "                shape = conv_var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                    (shape[3], shape[2], shape[0], shape[1]))\n",
    "                var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
    "            shape = bias.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(bias, var_weights))\n",
    "\n",
    "            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
    "            shape = conv_var.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "    return assign_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Running the model\n",
    "\n",
    "- 몇개의 샘플 이미지를 사용하여 모델을 돌려보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = ['../input/dog.jpg', '../input/office.jpg']\n",
    "for img in img_names: display(Image.open(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detections\n",
    "\n",
    "- 0.5로 세팅된 IOU 한계치를 가진 모델들과 Confidence threshold를 테스트 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(img_names)\n",
    "batch = load_images(img_names, model_size=_MODEL_SIZE)\n",
    "class_names = load_class_names('../input/coco.names')\n",
    "n_classes = len(class_names)\n",
    "max_output_size = 10\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE,\n",
    "                max_output_size=max_output_size,\n",
    "                iou_threshold=iou_threshold,\n",
    "                confidence_threshold=confidence_threshold)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
    "\n",
    "detections = model(inputs, training=False)\n",
    "\n",
    "model_vars = tf.global_variables(scope='yolo_v3_model')\n",
    "assign_ops = load_weights(model_vars, '../input/yolov3.weights')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(assign_ops)\n",
    "    detection_result = sess.run(detections, feed_dict={inputs: batch})\n",
    "    \n",
    "draw_boxes(img_names, detection_result, class_names, _MODEL_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
